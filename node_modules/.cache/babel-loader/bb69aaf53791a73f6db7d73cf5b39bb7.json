{"ast":null,"code":"exports.tokenize = tokenizeContent;\nexports.resolve = resolveContent;\nexports.interruptible = true;\nexports.lazy = true;\n\nvar markdownLineEnding = require('../character/markdown-line-ending');\n\nvar subtokenize = require('../util/subtokenize');\n\nvar prefixSize = require('../util/prefix-size');\n\nvar createSpace = require('./factory-space');\n\nvar lookaheadConstruct = {\n  tokenize: tokenizeLookaheadConstruct,\n  partial: true\n}; // Content is transparent: it’s parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous;\n  return start;\n\n  function start(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return data(code);\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(lookaheadConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n\n    effects.consume(code);\n    return data;\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    });\n    return data;\n  }\n}\n\nfunction tokenizeLookaheadConstruct(effects, ok, nok) {\n  var self = this;\n  return startLookahead;\n\n  function startLookahead(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return createSpace(effects, prefixed, 'linePrefix');\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    if (prefixSize(self.events, 'linePrefix') < 4) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n    }\n\n    return ok(code);\n  }\n}","map":{"version":3,"sources":["/home/boshra/personal/markdown-editor/node_modules/micromark/dist/tokenize/content.js"],"names":["exports","tokenize","tokenizeContent","resolve","resolveContent","interruptible","lazy","markdownLineEnding","require","subtokenize","prefixSize","createSpace","lookaheadConstruct","tokenizeLookaheadConstruct","partial","events","effects","ok","previous","start","code","enter","contentType","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","prefixed","interrupt","parser","constructs","flow"],"mappings":"AAAAA,OAAO,CAACC,QAAR,GAAmBC,eAAnB;AACAF,OAAO,CAACG,OAAR,GAAkBC,cAAlB;AACAJ,OAAO,CAACK,aAAR,GAAwB,IAAxB;AACAL,OAAO,CAACM,IAAR,GAAe,IAAf;;AAEA,IAAIC,kBAAkB,GAAGC,OAAO,CAAC,mCAAD,CAAhC;;AAEA,IAAIC,WAAW,GAAGD,OAAO,CAAC,qBAAD,CAAzB;;AACA,IAAIE,UAAU,GAAGF,OAAO,CAAC,qBAAD,CAAxB;;AACA,IAAIG,WAAW,GAAGH,OAAO,CAAC,iBAAD,CAAzB;;AAEA,IAAII,kBAAkB,GAAG;AAACX,EAAAA,QAAQ,EAAEY,0BAAX;AAAuCC,EAAAA,OAAO,EAAE;AAAhD,CAAzB,C,CAEA;AACA;;AACA,SAASV,cAAT,CAAwBW,MAAxB,EAAgC;AAC9BN,EAAAA,WAAW,CAACM,MAAD,CAAX;AACA,SAAOA,MAAP;AACD;;AAED,SAASb,eAAT,CAAyBc,OAAzB,EAAkCC,EAAlC,EAAsC;AACpC,MAAIC,QAAJ;AAEA,SAAOC,KAAP;;AAEA,WAASA,KAAT,CAAeC,IAAf,EAAqB;AACnBJ,IAAAA,OAAO,CAACK,KAAR,CAAc,SAAd;AACAH,IAAAA,QAAQ,GAAGF,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;AACvCC,MAAAA,WAAW,EAAE;AAD0B,KAA9B,CAAX;AAIA,WAAOC,IAAI,CAACH,IAAD,CAAX;AACD;;AAED,WAASG,IAAT,CAAcH,IAAd,EAAoB;AAClB,QAAIA,IAAI,KAAK,IAAb,EAAmB;AACjB,aAAOI,UAAU,CAACJ,IAAD,CAAjB;AACD;;AAED,QAAIb,kBAAkB,CAACa,IAAD,CAAtB,EAA8B;AAC5B,aAAOJ,OAAO,CAACS,KAAR,CACLb,kBADK,EAELc,eAFK,EAGLF,UAHK,EAILJ,IAJK,CAAP;AAKD,KAXiB,CAalB;;;AACAJ,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACA,WAAOG,IAAP;AACD;;AAED,WAASC,UAAT,CAAoBJ,IAApB,EAA0B;AACxBJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAZ,IAAAA,OAAO,CAACY,IAAR,CAAa,SAAb;AACA,WAAOX,EAAE,CAACG,IAAD,CAAT;AACD;;AAED,WAASM,eAAT,CAAyBN,IAAzB,EAA+B;AAC7BJ,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACAJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAV,IAAAA,QAAQ,GAAGA,QAAQ,CAACW,IAAT,GAAgBb,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;AACvDC,MAAAA,WAAW,EAAE,SAD0C;AAEvDJ,MAAAA,QAAQ,EAAEA;AAF6C,KAA9B,CAA3B;AAKA,WAAOK,IAAP;AACD;AACF;;AAED,SAASV,0BAAT,CAAoCG,OAApC,EAA6CC,EAA7C,EAAiDa,GAAjD,EAAsD;AACpD,MAAIC,IAAI,GAAG,IAAX;AAEA,SAAOC,cAAP;;AAEA,WAASA,cAAT,CAAwBZ,IAAxB,EAA8B;AAC5BJ,IAAAA,OAAO,CAACK,KAAR,CAAc,YAAd;AACAL,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACAJ,IAAAA,OAAO,CAACY,IAAR,CAAa,YAAb;AACA,WAAOjB,WAAW,CAACK,OAAD,EAAUiB,QAAV,EAAoB,YAApB,CAAlB;AACD;;AAED,WAASA,QAAT,CAAkBb,IAAlB,EAAwB;AACtB,QAAIA,IAAI,KAAK,IAAT,IAAiBb,kBAAkB,CAACa,IAAD,CAAvC,EAA+C;AAC7C,aAAOU,GAAG,CAACV,IAAD,CAAV;AACD;;AAED,QAAIV,UAAU,CAACqB,IAAI,CAAChB,MAAN,EAAc,YAAd,CAAV,GAAwC,CAA5C,EAA+C;AAC7C,aAAOC,OAAO,CAACkB,SAAR,CAAkBH,IAAI,CAACI,MAAL,CAAYC,UAAZ,CAAuBC,IAAzC,EAA+CP,GAA/C,EAAoDb,EAApD,EAAwDG,IAAxD,CAAP;AACD;;AAED,WAAOH,EAAE,CAACG,IAAD,CAAT;AACD;AACF","sourcesContent":["exports.tokenize = tokenizeContent\nexports.resolve = resolveContent\nexports.interruptible = true\nexports.lazy = true\n\nvar markdownLineEnding = require('../character/markdown-line-ending')\n\nvar subtokenize = require('../util/subtokenize')\nvar prefixSize = require('../util/prefix-size')\nvar createSpace = require('./factory-space')\n\nvar lookaheadConstruct = {tokenize: tokenizeLookaheadConstruct, partial: true}\n\n// Content is transparent: it’s parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous\n\n  return start\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        lookaheadConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    })\n\n    return data\n  }\n}\n\nfunction tokenizeLookaheadConstruct(effects, ok, nok) {\n  var self = this\n\n  return startLookahead\n\n  function startLookahead(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return createSpace(effects, prefixed, 'linePrefix')\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    if (prefixSize(self.events, 'linePrefix') < 4) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n    }\n\n    return ok(code)\n  }\n}\n"]},"metadata":{},"sourceType":"script"}