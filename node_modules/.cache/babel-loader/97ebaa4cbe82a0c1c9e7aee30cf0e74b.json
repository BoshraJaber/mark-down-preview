{"ast":null,"code":"module.exports = createTokenizer;\n\nvar assign = require('../constant/assign');\n\nvar markdownLineEnding = require('../character/markdown-line-ending');\n\nvar chunkedSplice = require('./chunked-splice');\n\nvar shallow = require('./shallow');\n\nvar serializeChunks = require('./serialize-chunks');\n\nvar sliceChunks = require('./slice-chunks');\n\nvar resolveAll = require('./resolve-all');\n\nvar miniflat = require('./miniflat'); // Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesn’t receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\n\n\nfunction createTokenizer(parser, initialize, from) {\n  var point = from ? shallow(from) : {\n    line: 1,\n    column: 1,\n    offset: 0\n  };\n  var columnStart = {};\n  var resolveAllConstructs = [];\n  var chunks = [];\n  var stack = [];\n  var consumed = true; // Tools used for tokenizing.\n\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    }),\n    lazy: constructFactory(onsuccessfulcheck, {\n      lazy: true\n    })\n  }; // State and tools for resolving and serializing.\n\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write\n  }; // The state function.\n\n  var state = initialize.tokenize.call(context, effects); // Track which character we expect to be consumed, to catch bugs.\n\n  var expectedCode;\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  } // Store where we are in the input stream.\n\n\n  point._index = 0;\n  point._bufferIndex = -1;\n  return context;\n\n  function write(slice) {\n    chunkedSplice(chunks, chunks.length, 0, slice);\n    main(); // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n\n    addResult(initialize, 0); // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  } //\n  // Tools.\n  //\n\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token));\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  function now() {\n    return shallow(point);\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  } //\n  // State management.\n  //\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n\n\n  function main() {\n    var chunkIndex;\n    var chunk;\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index]; // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  } // Deal with one code.\n\n\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  } // Move a character forward.\n\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    } // Not in a string chunk.\n\n\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++; // At end of string chunk.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    } // Expose the previous character.\n\n\n    context.previous = code; // Mark as consumed.\n\n    consumed = true;\n  } // Start a token.\n\n\n  function enter(type, fields) {\n    var token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  } // Stop a token.\n\n\n  function exit(type) {\n    var token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  } // Use results.\n\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  } // Discard results.\n\n\n  function onsuccessfulcheck(construct, info) {\n    info.restore();\n  } // Factory to attempt/check/interrupt.\n\n\n  function constructFactory(onreturn, fields) {\n    return hook; // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs;\n      var constructIndex;\n      var currentConstruct;\n      var info;\n      return constructs.tokenize || 'length' in constructs ? handleListOfConstructs(miniflat(constructs)) : handleMapOfConstructs;\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(\n          /* istanbul ignore next - `null` is used by some extensions */\n          constructs.null ? miniflat(constructs[code]).concat(miniflat(constructs.null)) : constructs[code])(code);\n        }\n\n        return bogusState(code);\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        return handleConstruct(list[constructIndex]);\n      }\n\n      function handleConstruct(construct) {\n        return start;\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          return construct.tokenize.call(fields ? assign({}, context, fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      function nok(code) {\n        consumed = true;\n        info.restore();\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n\n        return bogusState;\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct);\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  function store() {\n    var startPoint = now();\n    var startPrevious = context.previous;\n    var startCurrentConstruct = context.currentConstruct;\n    var startEventsIndex = context.events.length;\n    var startStack = Array.from(stack);\n    return {\n      restore: restore,\n      from: startEventsIndex\n    };\n\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}","map":{"version":3,"sources":["/home/boshra/personal/markdown-editor/node_modules/micromark/dist/util/create-tokenizer.js"],"names":["module","exports","createTokenizer","assign","require","markdownLineEnding","chunkedSplice","shallow","serializeChunks","sliceChunks","resolveAll","miniflat","parser","initialize","from","point","line","column","offset","columnStart","resolveAllConstructs","chunks","stack","consumed","effects","consume","enter","exit","attempt","constructFactory","onsuccessfulconstruct","check","onsuccessfulcheck","interrupt","lazy","context","previous","events","sliceStream","sliceSerialize","now","defineSkip","skip","write","state","tokenize","call","expectedCode","push","_index","_bufferIndex","slice","length","main","addResult","token","value","accountForPotentialSkip","chunkIndex","chunk","go","charCodeAt","code","undefined","type","fields","start","pop","end","construct","info","restore","onreturn","hook","constructs","returnState","bogusState","listOfConstructs","constructIndex","currentConstruct","handleListOfConstructs","handleMapOfConstructs","null","concat","list","handleConstruct","store","partial","ok","nok","indexOf","resolve","resolveTo","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","Array"],"mappings":"AAAAA,MAAM,CAACC,OAAP,GAAiBC,eAAjB;;AAEA,IAAIC,MAAM,GAAGC,OAAO,CAAC,oBAAD,CAApB;;AAEA,IAAIC,kBAAkB,GAAGD,OAAO,CAAC,mCAAD,CAAhC;;AACA,IAAIE,aAAa,GAAGF,OAAO,CAAC,kBAAD,CAA3B;;AACA,IAAIG,OAAO,GAAGH,OAAO,CAAC,WAAD,CAArB;;AACA,IAAII,eAAe,GAAGJ,OAAO,CAAC,oBAAD,CAA7B;;AACA,IAAIK,WAAW,GAAGL,OAAO,CAAC,gBAAD,CAAzB;;AACA,IAAIM,UAAU,GAAGN,OAAO,CAAC,eAAD,CAAxB;;AACA,IAAIO,QAAQ,GAAGP,OAAO,CAAC,YAAD,CAAtB,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASF,eAAT,CAAyBU,MAAzB,EAAiCC,UAAjC,EAA6CC,IAA7C,EAAmD;AACjD,MAAIC,KAAK,GAAGD,IAAI,GAAGP,OAAO,CAACO,IAAD,CAAV,GAAmB;AAACE,IAAAA,IAAI,EAAE,CAAP;AAAUC,IAAAA,MAAM,EAAE,CAAlB;AAAqBC,IAAAA,MAAM,EAAE;AAA7B,GAAnC;AACA,MAAIC,WAAW,GAAG,EAAlB;AACA,MAAIC,oBAAoB,GAAG,EAA3B;AACA,MAAIC,MAAM,GAAG,EAAb;AACA,MAAIC,KAAK,GAAG,EAAZ;AACA,MAAIC,QAAQ,GAAG,IAAf,CANiD,CAQjD;;AACA,MAAIC,OAAO,GAAG;AACZC,IAAAA,OAAO,EAAEA,OADG;AAEZC,IAAAA,KAAK,EAAEA,KAFK;AAGZC,IAAAA,IAAI,EAAEA,IAHM;AAIZC,IAAAA,OAAO,EAAEC,gBAAgB,CAACC,qBAAD,CAJb;AAKZC,IAAAA,KAAK,EAAEF,gBAAgB,CAACG,iBAAD,CALX;AAMZC,IAAAA,SAAS,EAAEJ,gBAAgB,CAACG,iBAAD,EAAoB;AAACC,MAAAA,SAAS,EAAE;AAAZ,KAApB,CANf;AAOZC,IAAAA,IAAI,EAAEL,gBAAgB,CAACG,iBAAD,EAAoB;AAACE,MAAAA,IAAI,EAAE;AAAP,KAApB;AAPV,GAAd,CATiD,CAmBjD;;AACA,MAAIC,OAAO,GAAG;AACZC,IAAAA,QAAQ,EAAE,IADE;AAEZC,IAAAA,MAAM,EAAE,EAFI;AAGZzB,IAAAA,MAAM,EAAEA,MAHI;AAIZ0B,IAAAA,WAAW,EAAEA,WAJD;AAKZC,IAAAA,cAAc,EAAEA,cALJ;AAMZC,IAAAA,GAAG,EAAEA,GANO;AAOZC,IAAAA,UAAU,EAAEC,IAPA;AAQZC,IAAAA,KAAK,EAAEA;AARK,GAAd,CApBiD,CA+BjD;;AACA,MAAIC,KAAK,GAAG/B,UAAU,CAACgC,QAAX,CAAoBC,IAApB,CAAyBX,OAAzB,EAAkCX,OAAlC,CAAZ,CAhCiD,CAkCjD;;AACA,MAAIuB,YAAJ;;AAEA,MAAIlC,UAAU,CAACH,UAAf,EAA2B;AACzBU,IAAAA,oBAAoB,CAAC4B,IAArB,CAA0BnC,UAA1B;AACD,GAvCgD,CAyCjD;;;AACAE,EAAAA,KAAK,CAACkC,MAAN,GAAe,CAAf;AACAlC,EAAAA,KAAK,CAACmC,YAAN,GAAqB,CAAC,CAAtB;AAEA,SAAOf,OAAP;;AAEA,WAASQ,KAAT,CAAeQ,KAAf,EAAsB;AACpB7C,IAAAA,aAAa,CAACe,MAAD,EAASA,MAAM,CAAC+B,MAAhB,EAAwB,CAAxB,EAA2BD,KAA3B,CAAb;AAEAE,IAAAA,IAAI,GAHgB,CAKpB;;AACA,QAAIhC,MAAM,CAACA,MAAM,CAAC+B,MAAP,GAAgB,CAAjB,CAAN,KAA8B,IAAlC,EAAwC;AACtC,aAAO,EAAP;AACD;;AAEDE,IAAAA,SAAS,CAACzC,UAAD,EAAa,CAAb,CAAT,CAVoB,CAYpB;;AACAsB,IAAAA,OAAO,CAACE,MAAR,GAAiB3B,UAAU,CAACU,oBAAD,EAAuBe,OAAO,CAACE,MAA/B,EAAuCF,OAAvC,CAA3B;AAEA,WAAOA,OAAO,CAACE,MAAf;AACD,GA/DgD,CAiEjD;AACA;AACA;;;AAEA,WAASE,cAAT,CAAwBgB,KAAxB,EAA+B;AAC7B,WAAO/C,eAAe,CAAC8B,WAAW,CAACiB,KAAD,CAAZ,CAAtB;AACD;;AAED,WAASjB,WAAT,CAAqBiB,KAArB,EAA4B;AAC1B,WAAO9C,WAAW,CAACY,MAAD,EAASkC,KAAT,CAAlB;AACD;;AAED,WAASf,GAAT,GAAe;AACb,WAAOjC,OAAO,CAACQ,KAAD,CAAd;AACD;;AAED,WAAS2B,IAAT,CAAcc,KAAd,EAAqB;AACnBrC,IAAAA,WAAW,CAACqC,KAAK,CAACxC,IAAP,CAAX,GAA0BwC,KAAK,CAACvC,MAAhC;AACAwC,IAAAA,uBAAuB;AACxB,GApFgD,CAsFjD;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;AACA,WAASJ,IAAT,GAAgB;AACd,QAAIK,UAAJ;AACA,QAAIC,KAAJ;;AAEA,WAAO5C,KAAK,CAACkC,MAAN,GAAe5B,MAAM,CAAC+B,MAA7B,EAAqC;AACnCO,MAAAA,KAAK,GAAGtC,MAAM,CAACN,KAAK,CAACkC,MAAP,CAAd,CADmC,CAGnC;;AACA,UAAI,OAAOU,KAAP,KAAiB,QAArB,EAA+B;AAC7BD,QAAAA,UAAU,GAAG3C,KAAK,CAACkC,MAAnB;;AAEA,YAAIlC,KAAK,CAACmC,YAAN,GAAqB,CAAzB,EAA4B;AAC1BnC,UAAAA,KAAK,CAACmC,YAAN,GAAqB,CAArB;AACD;;AAED,eACEnC,KAAK,CAACkC,MAAN,KAAiBS,UAAjB,IACA3C,KAAK,CAACmC,YAAN,GAAqBS,KAAK,CAACP,MAF7B,EAGE;AACAQ,UAAAA,EAAE,CAACD,KAAK,CAACE,UAAN,CAAiB9C,KAAK,CAACmC,YAAvB,CAAD,CAAF;AACD;AACF,OAbD,MAaO;AACLU,QAAAA,EAAE,CAACD,KAAD,CAAF;AACD;AACF;AACF,GAzHgD,CA2HjD;;;AACA,WAASC,EAAT,CAAYE,IAAZ,EAAkB;AAChBvC,IAAAA,QAAQ,GAAGwC,SAAX;AAEAhB,IAAAA,YAAY,GAAGe,IAAf;AACAlB,IAAAA,KAAK,GAAGA,KAAK,CAACkB,IAAD,CAAb;AACD,GAjIgD,CAmIjD;;;AACA,WAASrC,OAAT,CAAiBqC,IAAjB,EAAuB;AACrB,QAAIzD,kBAAkB,CAACyD,IAAD,CAAtB,EAA8B;AAC5B/C,MAAAA,KAAK,CAACC,IAAN;AACAD,MAAAA,KAAK,CAACE,MAAN,GAAe,CAAf;AACAF,MAAAA,KAAK,CAACG,MAAN,IAAgB4C,IAAI,KAAK,CAAC,CAAV,GAAc,CAAd,GAAkB,CAAlC;AACAL,MAAAA,uBAAuB;AACxB,KALD,MAKO,IAAIK,IAAI,KAAK,CAAC,CAAd,EAAiB;AACtB/C,MAAAA,KAAK,CAACE,MAAN;AACAF,MAAAA,KAAK,CAACG,MAAN;AACD,KAToB,CAWrB;;;AACA,QAAIH,KAAK,CAACmC,YAAN,GAAqB,CAAzB,EAA4B;AAC1BnC,MAAAA,KAAK,CAACkC,MAAN;AACD,KAFD,MAEO;AACLlC,MAAAA,KAAK,CAACmC,YAAN,GADK,CAGL;;AACA,UAAInC,KAAK,CAACmC,YAAN,KAAuB7B,MAAM,CAACN,KAAK,CAACkC,MAAP,CAAN,CAAqBG,MAAhD,EAAwD;AACtDrC,QAAAA,KAAK,CAACmC,YAAN,GAAqB,CAAC,CAAtB;AACAnC,QAAAA,KAAK,CAACkC,MAAN;AACD;AACF,KAtBoB,CAwBrB;;;AACAd,IAAAA,OAAO,CAACC,QAAR,GAAmB0B,IAAnB,CAzBqB,CA2BrB;;AACAvC,IAAAA,QAAQ,GAAG,IAAX;AACD,GAjKgD,CAmKjD;;;AACA,WAASG,KAAT,CAAesC,IAAf,EAAqBC,MAArB,EAA6B;AAC3B,QAAIV,KAAK,GAAGU,MAAM,IAAI,EAAtB;AACAV,IAAAA,KAAK,CAACS,IAAN,GAAaA,IAAb;AACAT,IAAAA,KAAK,CAACW,KAAN,GAAc1B,GAAG,EAAjB;AAEAL,IAAAA,OAAO,CAACE,MAAR,CAAeW,IAAf,CAAoB,CAAC,OAAD,EAAUO,KAAV,EAAiBpB,OAAjB,CAApB;AAEAb,IAAAA,KAAK,CAAC0B,IAAN,CAAWO,KAAX;AAEA,WAAOA,KAAP;AACD,GA9KgD,CAgLjD;;;AACA,WAAS5B,IAAT,CAAcqC,IAAd,EAAoB;AAClB,QAAIT,KAAK,GAAGjC,KAAK,CAAC6C,GAAN,EAAZ;AACAZ,IAAAA,KAAK,CAACa,GAAN,GAAY5B,GAAG,EAAf;AAEAL,IAAAA,OAAO,CAACE,MAAR,CAAeW,IAAf,CAAoB,CAAC,MAAD,EAASO,KAAT,EAAgBpB,OAAhB,CAApB;AAEA,WAAOoB,KAAP;AACD,GAxLgD,CA0LjD;;;AACA,WAASzB,qBAAT,CAA+BuC,SAA/B,EAA0CC,IAA1C,EAAgD;AAC9ChB,IAAAA,SAAS,CAACe,SAAD,EAAYC,IAAI,CAACxD,IAAjB,CAAT;AACD,GA7LgD,CA+LjD;;;AACA,WAASkB,iBAAT,CAA2BqC,SAA3B,EAAsCC,IAAtC,EAA4C;AAC1CA,IAAAA,IAAI,CAACC,OAAL;AACD,GAlMgD,CAoMjD;;;AACA,WAAS1C,gBAAT,CAA0B2C,QAA1B,EAAoCP,MAApC,EAA4C;AAC1C,WAAOQ,IAAP,CAD0C,CAG1C;AACA;;AACA,aAASA,IAAT,CAAcC,UAAd,EAA0BC,WAA1B,EAAuCC,UAAvC,EAAmD;AACjD,UAAIC,gBAAJ;AACA,UAAIC,cAAJ;AACA,UAAIC,gBAAJ;AACA,UAAIT,IAAJ;AAEA,aAAOI,UAAU,CAAC7B,QAAX,IAAuB,YAAY6B,UAAnC,GACHM,sBAAsB,CAACrE,QAAQ,CAAC+D,UAAD,CAAT,CADnB,GAEHO,qBAFJ;;AAIA,eAASA,qBAAT,CAA+BnB,IAA/B,EAAqC;AACnC,YAAIA,IAAI,IAAIY,UAAR,IAAsB,QAAQA,UAAlC,EAA8C;AAC5C,iBAAOM,sBAAsB;AAC3B;AACAN,UAAAA,UAAU,CAACQ,IAAX,GACIvE,QAAQ,CAAC+D,UAAU,CAACZ,IAAD,CAAX,CAAR,CAA2BqB,MAA3B,CAAkCxE,QAAQ,CAAC+D,UAAU,CAACQ,IAAZ,CAA1C,CADJ,GAEIR,UAAU,CAACZ,IAAD,CAJa,CAAtB,CAKLA,IALK,CAAP;AAMD;;AAED,eAAOc,UAAU,CAACd,IAAD,CAAjB;AACD;;AAED,eAASkB,sBAAT,CAAgCI,IAAhC,EAAsC;AACpCP,QAAAA,gBAAgB,GAAGO,IAAnB;AACAN,QAAAA,cAAc,GAAG,CAAjB;AACA,eAAOO,eAAe,CAACD,IAAI,CAACN,cAAD,CAAL,CAAtB;AACD;;AAED,eAASO,eAAT,CAAyBhB,SAAzB,EAAoC;AAClC,eAAOH,KAAP;;AAEA,iBAASA,KAAT,CAAeJ,IAAf,EAAqB;AACnB;AACA;AACA;AACA;AACAQ,UAAAA,IAAI,GAAGgB,KAAK,EAAZ;AACAP,UAAAA,gBAAgB,GAAGV,SAAnB;;AAEA,cAAI,CAACA,SAAS,CAACkB,OAAf,EAAwB;AACtBpD,YAAAA,OAAO,CAAC4C,gBAAR,GAA2BV,SAA3B;AACD;;AAED,iBAAOA,SAAS,CAACxB,QAAV,CAAmBC,IAAnB,CACLmB,MAAM,GAAG9D,MAAM,CAAC,EAAD,EAAKgC,OAAL,EAAc8B,MAAd,CAAT,GAAiC9B,OADlC,EAELX,OAFK,EAGLgE,EAHK,EAILC,GAJK,EAKL3B,IALK,CAAP;AAMD;AACF;;AAED,eAAS0B,EAAT,CAAY1B,IAAZ,EAAkB;AAChBvC,QAAAA,QAAQ,GAAG,IAAX;AACAiD,QAAAA,QAAQ,CAACO,gBAAD,EAAmBT,IAAnB,CAAR;AACA,eAAOK,WAAP;AACD;;AAED,eAASc,GAAT,CAAa3B,IAAb,EAAmB;AACjBvC,QAAAA,QAAQ,GAAG,IAAX;AACA+C,QAAAA,IAAI,CAACC,OAAL;;AAEA,YAAI,EAAEO,cAAF,GAAmBD,gBAAgB,CAACzB,MAAxC,EAAgD;AAC9C,iBAAOiC,eAAe,CAACR,gBAAgB,CAACC,cAAD,CAAjB,CAAtB;AACD;;AAED,eAAOF,UAAP;AACD;AACF;AACF;;AAED,WAAStB,SAAT,CAAmBe,SAAnB,EAA8BvD,IAA9B,EAAoC;AAClC,QAAIuD,SAAS,CAAC3D,UAAV,IAAwBU,oBAAoB,CAACsE,OAArB,CAA6BrB,SAA7B,IAA0C,CAAtE,EAAyE;AACvEjD,MAAAA,oBAAoB,CAAC4B,IAArB,CAA0BqB,SAA1B;AACD;;AAED,QAAIA,SAAS,CAACsB,OAAd,EAAuB;AACrBrF,MAAAA,aAAa,CACX6B,OAAO,CAACE,MADG,EAEXvB,IAFW,EAGXqB,OAAO,CAACE,MAAR,CAAee,MAAf,GAAwBtC,IAHb,EAIXuD,SAAS,CAACsB,OAAV,CAAkBxD,OAAO,CAACE,MAAR,CAAec,KAAf,CAAqBrC,IAArB,CAAlB,EAA8CqB,OAA9C,CAJW,CAAb;AAMD;;AAED,QAAIkC,SAAS,CAACuB,SAAd,EAAyB;AACvBzD,MAAAA,OAAO,CAACE,MAAR,GAAiBgC,SAAS,CAACuB,SAAV,CAAoBzD,OAAO,CAACE,MAA5B,EAAoCF,OAApC,CAAjB;AACD;AACF;;AAED,WAASmD,KAAT,GAAiB;AACf,QAAIO,UAAU,GAAGrD,GAAG,EAApB;AACA,QAAIsD,aAAa,GAAG3D,OAAO,CAACC,QAA5B;AACA,QAAI2D,qBAAqB,GAAG5D,OAAO,CAAC4C,gBAApC;AACA,QAAIiB,gBAAgB,GAAG7D,OAAO,CAACE,MAAR,CAAee,MAAtC;AACA,QAAI6C,UAAU,GAAGC,KAAK,CAACpF,IAAN,CAAWQ,KAAX,CAAjB;AAEA,WAAO;AAACiD,MAAAA,OAAO,EAAEA,OAAV;AAAmBzD,MAAAA,IAAI,EAAEkF;AAAzB,KAAP;;AAEA,aAASzB,OAAT,GAAmB;AACjBxD,MAAAA,KAAK,GAAG8E,UAAR;AACA1D,MAAAA,OAAO,CAACC,QAAR,GAAmB0D,aAAnB;AACA3D,MAAAA,OAAO,CAAC4C,gBAAR,GAA2BgB,qBAA3B;AACA5D,MAAAA,OAAO,CAACE,MAAR,CAAee,MAAf,GAAwB4C,gBAAxB;AACA1E,MAAAA,KAAK,GAAG2E,UAAR;AACAxC,MAAAA,uBAAuB;AACxB;AACF;;AAED,WAASA,uBAAT,GAAmC;AACjC,QAAI1C,KAAK,CAACC,IAAN,IAAcG,WAAd,IAA6BJ,KAAK,CAACE,MAAN,GAAe,CAAhD,EAAmD;AACjDF,MAAAA,KAAK,CAACE,MAAN,GAAeE,WAAW,CAACJ,KAAK,CAACC,IAAP,CAA1B;AACAD,MAAAA,KAAK,CAACG,MAAN,IAAgBC,WAAW,CAACJ,KAAK,CAACC,IAAP,CAAX,GAA0B,CAA1C;AACD;AACF;AACF","sourcesContent":["module.exports = createTokenizer\n\nvar assign = require('../constant/assign')\n\nvar markdownLineEnding = require('../character/markdown-line-ending')\nvar chunkedSplice = require('./chunked-splice')\nvar shallow = require('./shallow')\nvar serializeChunks = require('./serialize-chunks')\nvar sliceChunks = require('./slice-chunks')\nvar resolveAll = require('./resolve-all')\nvar miniflat = require('./miniflat')\n\n// Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesn’t receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\nfunction createTokenizer(parser, initialize, from) {\n  var point = from ? shallow(from) : {line: 1, column: 1, offset: 0}\n  var columnStart = {}\n  var resolveAllConstructs = []\n  var chunks = []\n  var stack = []\n  var consumed = true\n\n  // Tools used for tokenizing.\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {interrupt: true}),\n    lazy: constructFactory(onsuccessfulcheck, {lazy: true})\n  }\n\n  // State and tools for resolving and serializing.\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write\n  }\n\n  // The state function.\n  var state = initialize.tokenize.call(context, effects)\n\n  // Track which character we expect to be consumed, to catch bugs.\n  var expectedCode\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n\n  // Store where we are in the input stream.\n  point._index = 0\n  point._bufferIndex = -1\n\n  return context\n\n  function write(slice) {\n    chunkedSplice(chunks, chunks.length, 0, slice)\n\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token))\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  function now() {\n    return shallow(point)\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  }\n\n  //\n  // State management.\n  //\n\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n  function main() {\n    var chunkIndex\n    var chunk\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  // Deal with one code.\n  function go(code) {\n    consumed = undefined\n\n    expectedCode = code\n    state = state(code)\n  }\n\n  // Move a character forward.\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  // Start a token.\n  function enter(type, fields) {\n    var token = fields || {}\n    token.type = type\n    token.start = now()\n\n    context.events.push(['enter', token, context])\n\n    stack.push(token)\n\n    return token\n  }\n\n  // Stop a token.\n  function exit(type) {\n    var token = stack.pop()\n    token.end = now()\n\n    context.events.push(['exit', token, context])\n\n    return token\n  }\n\n  // Use results.\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  // Discard results.\n  function onsuccessfulcheck(construct, info) {\n    info.restore()\n  }\n\n  // Factory to attempt/check/interrupt.\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs\n      var constructIndex\n      var currentConstruct\n      var info\n\n      return constructs.tokenize || 'length' in constructs\n        ? handleListOfConstructs(miniflat(constructs))\n        : handleMapOfConstructs\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(\n            /* istanbul ignore next - `null` is used by some extensions */\n            constructs.null\n              ? miniflat(constructs[code]).concat(miniflat(constructs.null))\n              : constructs[code]\n          )(code)\n        }\n\n        return bogusState(code)\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        return handleConstruct(list[constructIndex])\n      }\n\n      function handleConstruct(construct) {\n        return start\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          return construct.tokenize.call(\n            fields ? assign({}, context, fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      function nok(code) {\n        consumed = true\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  function store() {\n    var startPoint = now()\n    var startPrevious = context.previous\n    var startCurrentConstruct = context.currentConstruct\n    var startEventsIndex = context.events.length\n    var startStack = Array.from(stack)\n\n    return {restore: restore, from: startEventsIndex}\n\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n"]},"metadata":{},"sourceType":"script"}